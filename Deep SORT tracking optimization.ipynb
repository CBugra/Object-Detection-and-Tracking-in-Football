{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIMIZED TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x512 20 persons, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.4ms\n",
      "Speed: 2.0ms preprocess, 41.4ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.0ms\n",
      "Speed: 1.4ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.9ms\n",
      "Speed: 2.0ms preprocess, 41.9ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 4.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 40.5ms\n",
      "Speed: 2.0ms preprocess, 40.5ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.4ms\n",
      "Speed: 3.0ms preprocess, 41.4ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.6ms\n",
      "Speed: 0.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 18 persons, 41.4ms\n",
      "Speed: 1.2ms preprocess, 41.4ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 41.6ms\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 19 persons, 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 40.9ms\n",
      "Speed: 2.6ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 20 persons, 43.4ms\n",
      "Speed: 1.0ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 40.9ms\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 1 sports ball, 42.1ms\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 43.7ms\n",
      "Speed: 2.2ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 44.4ms\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.1ms\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.3ms\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 43.2ms\n",
      "Speed: 2.1ms preprocess, 43.2ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 42.8ms\n",
      "Speed: 1.0ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.9ms\n",
      "Speed: 2.0ms preprocess, 41.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 41.8ms\n",
      "Speed: 1.0ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 41.2ms\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.0ms\n",
      "Speed: 2.9ms preprocess, 41.0ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 21 persons, 44.3ms\n",
      "Speed: 1.1ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 42.7ms\n",
      "Speed: 1.3ms preprocess, 42.7ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 3.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 40.8ms\n",
      "Speed: 2.9ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 42.2ms\n",
      "Speed: 1.7ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 41.2ms\n",
      "Speed: 2.2ms preprocess, 41.2ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 24 persons, 43.1ms\n",
      "Speed: 2.3ms preprocess, 43.1ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 42.0ms\n",
      "Speed: 3.6ms preprocess, 42.0ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 41.2ms\n",
      "Speed: 1.1ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.5ms\n",
      "Speed: 2.4ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 43.6ms\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 22 persons, 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "0: 288x512 23 persons, 41.6ms\n",
      "Speed: 1.5ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import cupy as cp  # import CuPy for GPU acceleration\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# load YOLOv8 model to run on the GPU\n",
    "model = YOLO(r'C:\\Users\\hp\\Desktop\\Master_Thesis_Project\\Thesis Project\\Final Thesis Project\\New_Run\\New_Run\\Scenario 1\\train\\train\\weights\\best.pt').to(device)\n",
    "\n",
    "# initialize Deep SORT tracker\n",
    "tracker = DeepSort(\n",
    "    max_age=150,       # assigns a new ID if the object doesn't appear in 150 frames\n",
    "    n_init=5,          # increases confirmation count to reduce false positives for ID assignment\n",
    "    nn_budget=100,     # keeps more historical embeddings to improve correct ID assignments\n",
    "    max_iou_distance=0.30  # matches detected objects more carefully using IoU\n",
    ")\n",
    "\n",
    "video_path = r'C:\\Users\\hp\\Desktop\\Master_Thesis_Project\\Dataset\\Filtered_Video Dataset\\filtered_video_4.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# set up parameters for saving the output video\n",
    "output_video_path = r'C:\\Users\\hp\\Desktop\\Master_Thesis_Project\\Thesis Project\\Final Thesis Project\\Video & Image Output\\output4.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = None\n",
    "\n",
    "# process the video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # this step provides GPU acceleration\n",
    "    frame_gpu = cp.asarray(frame)\n",
    "\n",
    "    # convert cuPy array back to numPy array\n",
    "    frame_numpy = cp.asnumpy(frame_gpu)\n",
    "\n",
    "    # using the frame in NumPy format\n",
    "    results = model(frame_numpy)\n",
    "\n",
    "    # format the detected objects\n",
    "    detections = []\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            # extract coordinates (x1, y1, x2, y2) and detection confidence from YOLOv8\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())  # move detection from GPU to CPU\n",
    "            w = x2 - x1  # width\n",
    "            h = y2 - y1  # height\n",
    "            confidence = box.conf[0].item()  # confidence score\n",
    "            class_id = int(box.cls[0])  # class label\n",
    "            \n",
    "            detections.append(([x1, y1, w, h], confidence, class_id))\n",
    "\n",
    "    # track objects using Deep SORT\n",
    "    tracks = tracker.update_tracks(detections, frame=frame_numpy)\n",
    "\n",
    "    # draw the tracked objects\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()  # returns left, top, right, bottom\n",
    "        x1, y1, x2, y2 = map(int, ltrb)\n",
    "\n",
    "        # draw the tracked bounding box and ID\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID: {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # write output video\n",
    "    if out is None:\n",
    "        height, width, _ = frame.shape\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, 30, (width, height))\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "# release video source\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
